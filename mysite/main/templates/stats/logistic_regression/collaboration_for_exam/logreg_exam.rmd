---
title: 'Binary and multinomial logistic regression analysis'
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
    df_print: paged
    theme: default
bibliography: /Users/henrikeckermann/Documents/workspace/BibTex/statistic.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
library(knitr)
rmarkdown::render_site
```


*This document covers all the functions that Bill mentions in the lecture or used in his script about binary and multinomial logistic regression. The order of functions is as you would use them to perform logistic regression. How to use this file for the exam: Scroll through this file and look at the table of content on the left side. For each subchapter, functions that Bill used will appear. Whenever you see a function you don't know, check it out. For each function, the package to which it belongs is mentioned in parenthesis. If no package is mentioned, the function belongs to the basic R environment. Also, for each function a short description is given and the arguments that Bill presented are mentioned (not all possible arguments are listed and in very obvious cases I don't mention the arguments or only mention them in the short written description). The assumptions, including the functions needed to test them, are listed but the concepts behind logistic regression and the assumptions are only covered very superficially like in the lecture since we already did that in the first course. I think if you cover and understand this document you will be able to answer all exam questions about logistic regression and multinomial regression. However, I want to note that I would not perform this type of analysis in the way it is presented here and I also would not present assumption testing in the way it was shown to us. The focus here is merely to prepare for the exam*


# Binary logistic regression

## Import data

### read.spss (foreign)  

Used to import data from the *.SAV* fileformat that is used by SPSS. 

###### to.data.frame  

Logical: Store as dataframe (it would otherwise we stored in a list format in the below example)

  
###### use.value.labels  

Logical: Lets R convert variables with value labels into R factors. Alternatively, you could leave it out and specify factors manually by using `factor(variable_name)`

```{r}
library(foreign)
#optional: specify filename beforehand
filename <- 'https://github.com/HenrikEckermann/website/raw/master/mysite/main/templates/stats/logistic_regression/collaboration_for_exam/logreg.sav'
#the filename can be any direct link to the file. So, a filepath to a directory or a link like the one that I stored in the variable 'filename'
df <- read.spss(filename, to.data.frame=TRUE, use.value.labels=TRUE)
#The result is a dataframe:
head(df)
```

## Missing value analysis

### aggr (VIM)
Use this function to analyze patterns of missingness:

###### numbers
Logical: Indicates whether the proportion or frequencies of the different combinations should be represented by numbers in the output.  

###### prop 
Logical: Indicates whether the proportion of missing/imputed values and combinations should be used rather than the total amount.  

```{r}
library(VIM)
aggr(df, numbers=TRUE, prop=F)
```

### histMiss (VIM)
To check for patterns of missingness between two variables. Here age and satjob are compared. We see that with increasing age there is more missingness occuring for the variable _satjob_.

```{r}
histMiss(df[,c('age','satjob')])
```


### subset
Since there are a lot of missing values, Bill performed the analyses only on a subset of the variables. He used this subset function but also presented the alternatives shown further below.

###### boolean selection (logicals)
To select rows, in this example an expression is used that results in either TRUE or FALSE. 

###### select
This argument here takes a character vector that specifies which columns will be included.


```{r}
#Before subsetting
head(df)
#subsetting
df_sub <- subset(df, satjob!=FALSE & life != FALSE, select=c('id', 'sex', 'satjob', 'life'))
#after subsetting
head(df_sub)
```

### complete.cases & na.omit

Alternative to subset.

```{r}
#using complete.cases
df_sub1 <- df[complete.cases(df), c(1, 3, 4, 7)]
head(df_sub1)
#using na.omit 
df_sub2 <- na.omit(df[,c(1, 3, 4, 7)])
head(df_sub2)
```

## Fit model 

### glm 
This function is used to perform the logistic regression.

###### model 
Specify the model with the notation like you are used to from the function `lm()`.

###### data 
Specifies the dataframe where the data is stored.

###### family 
Specifies the probability distribution function that is used for the generalized linear model. For logistic regression we will use the _binomial distribution_.

_Note:_  
_Bill notes that the default of the glm function is to use listwise deletion._

```{r}
logmodel <- glm(satjob ~ sex + life, data=df_sub, family=binomial())
#model with interaction
logmodel2 <- glm(satjob ~ sex * life, data = df_sub, family = binomial())
```

### relevel 
In this example, to directly see whether routine&exciting lifestyles differ on job satisfaction, you need to let R pick a different reference group. One way is to change the order of the levels of the factor lifestyle with the function `relevel()`:

```{r}
df_sub$life <- relevel(df_sub$life, ref=2)
logmodel1 <- glm(satjob ~ sex + life, data=df_sub, family=binomial())
# here you can see that the reference group is now different:
summary(logmodel)
summary(logmodel1)
```

## Assumption 1: Linearity 
There should be a linear relationship between any continuous variable and the logit of the outcome. This can be tested by examining the interaction between the continuous predictor and its log transformation (only for continuous predictors). Since, in this example there are no continuous variables, I simulate a continuous variable to show how this looks in R. Just check if the interaction is significant. If yes, then the assumption is violated.

_Note:_  
_The function_ `rnorm()` _is covered in the introduction where we learned about simulating data._

```{r}
#simulate a continuous pred 
df_sub$cont_pred <- rnorm(754,10,2)
#check linearity assumption 
##first create interaction term between cont_pred and its log 
df_sub$cont_pred_int <- log(df_sub$cont_pred)*df_sub$cont_pred
#run the model with the interaction included. If the interaction term is significant, then the assumption of linearity is violated
logmodel3 <- glm(satjob ~ cont_pred + cont_pred_int, data = df_sub, family = binomial())
summary(logmodel3)
```

## Assumption 2: Independence of errors

### dwt (car)
To check for independence of errors. Values <1 or >3 indicate violation. The close to 2, the better. Just enter the model as argument as follows:  


```{r}
library(car)
dwt(logmodel)
```
## Assumption 3: Multicolliniearity
We check multicollinearity with the variance inflation factor. For continuous predictors (which are not in this example) the GVIF can be used. For categorical predictors the $GVIF^{\frac{1}{2*Df}}$ should be used. Values above 10 indicate a problem.

### vif (car)
Only argument needed is the model.

```{r}
vif(logmodel)
```





## Outliers & Influential cases
Bill presents 3 steps to check for outliers and influential cases as well as some diagnostic plots:  


1. Examine standardized residuals (to identify outliers)  
* 5% of cases should have residuals > 2  
* 1% should have residuals > 2.5
* None should be >3  
* It is not a general rule but Bill considers residuals with an absolute value >3 as outliers

### rstandard
To obtain the standardized residuals. The only argument needed is the general linear model (here the logistic regression model). Below I also use the functions `sum()`, `mean()` and `abs()`. I assumed that these are self explanatory because we all used them very often already.

```{r}
#store sresids in dataframe
df_sub$sresiduals <- rstandard(logmodel)
#check the criteria mentioned above
mean(abs(df_sub$sresiduals)>2)
mean(abs(df_sub$sresiduals)>2.5)
sum(abs(df_sub$sresiduals)>3)
#plot (see below for function explanation)
library(lattice)
densityplot(df_sub$sresiduals)
```

### densityplot (lattice)
As the functionname implies, it creates a densityplot of the values that are passed in as an argument. There are several options available but these have not been presented in the material of logistic regression but should be covered in the graphics section or the introduction section.

```{r}
library(lattice)
densityplot(df_sub$sresiduals)
```




2. Examine DFBetas (to identify influential cases)  
* no value should be above 1

### dfbeta
Again, use the model as argument and it will return the dfbeta values:

```{r}
dfbeta_val <- dfbeta(logmodel)
sum(abs(dfbeta_val>1))
max(dfbeta_val)
hist(dfbeta_val)
```

3. Calculate leverage (to identify influential cases)  
* Calculate: $\frac{k+1}{n}$, where k is the number of predictors
* Values larger than 2x or 3x the resulting value can be considered influential cases

### hatvalues

With this function we can easily get the hatvalues (leverage of values). Again, the only argument needed is the model. I apply the rules mentioned above as well:

```{r}
df_sub$leverage <- hatvalues(logmodel)
cutoff <- 3*(2+1)/(754)
sum(df_sub$leverage>cutoff)
densityplot(df_sub$leverage)

```




## Model evaluation and interpretation

```{r}
summary(logmodel)
```


To evaluate whether a single predictor is significant, you could look at the **z-statistic (or Wald statistic)**. Above, the coefficients of lifeRoutine and lifeExciting are significant according to this statistic. However, several authors depreciate the use of this statistic for different reasons. @Field2012 mentions that large coefficients could make the SE inflate, leading to underestimation of the z-statistic.  


To assess model fit, we always compare the baseline model with the new model. The most basic model only has the intercept and predicts according to the frequencies given in the dataset. Analogous to the statistics that reflect the unexplained variance  of the model in linear regression (e.g. RSS), for the logistic regression model we have the **log-likelihood** (LL). The higher the LL, the more variance is left unexplained by the model. We therefore use the LL to compare models. But instead of using the LL directly, we calculate the **deviance**, which is $-2*LL$ because this statistic follows the $\chi^2$ distribution and therefore allows for hypothesis testing. To check whether a model is better than another model (the one model must be nested in the other), we calculate the difference in the deviance (**likelihood-ratio**) and check whether this difference is significant:

$\chi^2 = -2*LL_{baseline}-(-2*LL_{new})$, with  $df = k_{new} -k_{baseline}$

I show below how to obtain the deviance of a model. Note that if you test a model against the model with only the intercept, you use the null-deviance. But if you compare models that have predictors you need to obtain the deviance of both models. Once you have the deviance statistics, you also obtain the degrees of freedom of and use the function `pchisq()` to calculate the likelihood ratio with the above formula and check the p-value of the likelihood ratio.


### pchisq
This function returns the p-value for a certain $\chi^2$ statistic. You need to pass in the following two arguments as shown in the example below. 

###### $\chi^2$ statistic 

###### degrees of freedom

```{r}
baseline_deviance <- logmodel$null.deviance
new_deviance <- logmodel$deviance
modelChi <- baseline_deviance - new_deviance
chi_df <- logmodel$df.null - logmodel$df.residual
chisq.prob <- 1 - pchisq(modelChi, chi_df)
modelChi; chi_df; chisq.prob
```

Thus, in this case the new model predicts the outcome significantly better than the baseline model.

### anova
As an alternative, we can use the function 'anova()' to let it check the difference between two models. Here I compare logmodel2 with logmodel1 instead of logmodel1 against the nullmodel. It shows the likelihood-ratio (under deviance) but it does not calculate the significance.

```{r}
anv_object <- anova(logmodel, logmodel2)
anv_object
anv_object$Deviance[2]
```

We can also obtain different _pseudo R-squares_ and use them as an effect size of our model. Bill does not explain much about them. I think it is sufficient if we know that there exist these analogues to $R^2$ (in linear regression) and that you can interpret them more or less in a similar way. Maybe also remember their names. I don't think that we need to remember the formula's to calculate them. Here is how you can calculate them in R:  

```{r}
#Hosmer & Lemeshow's
R2.hl<-modelChi/logmodel$null.deviance
#Cox & Snell's
R.cs <- 1 - exp ((logmodel$deviance - logmodel$null.deviance)/754)
#Nagelkerke's
R.n <- R.cs /( 1- ( exp (-(logmodel$null.deviance/ 754))))
R2.hl; R.cs; R.n
```


## oddsratios

The oddsratio for predictor $X_1$ are $e^{b_1}$ and can be interpreted as a factor by which the odds of the outcome happening change for a one unit increase in $X_1$. If the oddsratio is 1, then the odds of the outcome remain unchanged. Bill mentions in his presentation that he wants us to take the inverse but he gets confused himself and makes mistakes at this point. I don't know why he has a problem just reporting the oddsratio but I know that he cut off points in the last exam so if someone does know and is able to explain what he wants instead, maybe send me a message and I will add the explanation here. Remember that the exponentiated confidence intervals for oddsratios should not include 1 for the coefficient to be a significant predictor as opposed to 0 for coefficients in e.g. linear regression.

### exp 
This is the math function that represents $e^(x)$. We can use it to interpret the coefficients as odds ratio.

```{r}
exp(logmodel$coefficients)
#the confint function is self-explanatory...
exp(confint(logmodel))
```


# Multinomial logistic regression 

Since we have more than 2 categories in the outcome variable, we need to choose a reference group. The other two categories are then compared to this reference group. If you would want to change the reference group, you can use the function `relevel()` or you simply specify it with the argument 'reflevel' in the function `mlogit`. There is also an additional assumption. Finally, instead of the function `glm()`, you have to use the `mlogit()` function (this function is somewhat different to what we know from lm what about the model specification). But for the rest everything is the same. So, if you understand the concepts of binary LR, then you can apply them here. The model diagnostics is exactly the same. But you should know that Andy Field does not show how to obtain hatvalues and dfbeta and Bill did write in his script that he was unable to do that. You can do this by hand in R but I am sure they do not expect this from us. Once you have these values, the interpretation would be the same.

**Additional Assumption: Independence of Irrelevant Alternatives (IIA)**:  
The odds of choosing A over B should not depend on whether some other alternative C is present or absent. There are the _Hausman-McFadden test_ and the _Small-Hsiao test_. 

### mlogit.data (mlogit)   
The function mlogit requires the date to be in a specific format. The function `mlogit.data()` can be used to achieve this. Bill used the following function arguments:  

###### choice   
The variable name of the outcome as a string.
###### shape   
You could choose 'wide' or 'long'. Bill chose wide in the provided Rscript. 

```{r}
library(mlogit)
mlog1 <-mlogit.data(df_sub, choice ="life", shape ="wide")
head(mlog1)
```

### mlogit (mlogit)  

This is the function we use to fit the multinomial logistic regression model. The specification of the model is different compared to what we are used to. The difference is mentioned under the _model_ argument.

###### model  
The specification of the model is different than we are used to because we include a '1' followed by '|' to specify the intercept.  

###### data  
Dataframe as we are used to.  

###### reflevel   
Reference group.

```{r}
mlogmodel1<-mlogit(life ~ 1|sex * satjob, data = mlog1, reflevel = 1)
mlogmodel2<-mlogit(life ~ 1|sex * satjob, data = mlog1, reflevel = 2)

#residuals and fitted values can be obtained from the model
df_diag <- c(mlogmodel1$residuals, mlogmodel1$fitted.values)

#check out the model
summary(mlogmodel1)
summary(mlogmodel2)
```

This model output already shows the likelihood ratio test. This test here compares the model with predictors against the baseline model. If significant, it means that the model explains more variance than the baseline model. Instead of the deviance it also puts out the log-likelihood. So beware that if you want to calculate the likelihood ratio between two models that you need to multiply this by -2 to get deviance.




```{r}
#oddsratios with CIs
data.frame(exp(mlogmodel2$coefficients))
exp(confint(mlogmodel2))
```

The interpretation is exactly the same as with binary logistic regression. Remember that we specified a reference category above. In the model printed below the reference group is _exciting_. There is one significant predictor in the model below: Being not satisfied increases the odds of having a routine lifestyle by 3.07 (the odds of having routine life style versus exciting lifestyle). Remember that Bill wants us to report the odds ratio in a different way.

```{r}
summary(mlogmodel2)
```


