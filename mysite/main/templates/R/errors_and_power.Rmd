---
title: "Effect size, errors and power"
output:
  html_document: default
  html_notebook: default
---


When we perform hypothesis tests, we have a Null-hypothesis and at least one alternative hypothesis.

Rejecting the Null-Hypothesis when it is true is called **type one error** (false positive).  
Keeping the Null-Hypothesis when it is false is called **type two error** (false negative).

The chance that we reject the Null-Hypothesis based on a statistical test correctly, is the **power** of that statistical test.  

The power depends on the number of data points we have (N), the effect size and the **Alpha-value** we choose (by convention it is 0.05 or 0.01 but this is arbitrary - more important here is to make informed decisions).  

With high enough N we could reach a significant p-value (p-value < alpha-value) even with meaningless effect sizes. Therefore, we also need to determine when an effect size is meaningful.

When we plan to use hypothesis testing we thus need to calculate how large N must be to be sure that our statistical test has enough power to detect a certain effect size. We need to calculate this **before** we perform scientific experiments.

It is then more reasonable to present the effect size and a confidence interval rather than a p-value.

## Let's see how this looks in practice:
We have here a large dataset (N=1236) with measurement of the birth weight of babies of smoking and non-smoking mothers.

### Import Data libraries:
```{r}
library(rafalib)
library(dplyr)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
filename <- basename(url)
download.file(url, destfile=filename)
babies <- read.table("babies.txt", header=TRUE)
```
### Split into two groups:
```{r}
bwt.nonsmoke <- filter(babies, smoke==0) %>% select(bwt) %>% unlist
bwt.smoke <- filter(babies, smoke==1) %>% select(bwt) %>% unlist
```


### Standard deviations and difference in mean
Assume that this large dataset is the whole population, then we know that there is a difference in birthweight of 8.9 ounces
```{r}
mean(bwt.nonsmoke)
mean(bwt.smoke)
mean(bwt.nonsmoke)-mean(bwt.smoke)
popsd(bwt.nonsmoke)
popsd(bwt.smoke)
```


### Trade off between power and type I error:
Imagine we had only a small sample size. In this example we can see how this can lead to a type II error. The p-value is 0.1366428, which would prevent us from rejecting the Null-Hypothesis.
```{r}
set.seed(1)
nonsmoke <- sample(bwt.nonsmoke,5)
smoke <- sample(bwt.smoke,5)
t.test(nonsmoke, smoke)$p.value
```
As explained above, we could use the _pwr package_ to calcutlate the power of our test (or calculate how large N must be if you have the power ÃŸ). We would need N, the estimated effect size and the alpha value. Here, we can calculate the power manually by repeating the above experiment 10.000 times and see how often the Null-Hypothesis is rejected correctly:
```{r}
set.seed(1)
reject <- function(N, alpha=0.05){
  nonsmoke <- sample(bwt.nonsmoke,N)
  smoke <- sample(bwt.smoke,N)
  pval <- t.test(nonsmoke, smoke)$p.value
  pval < alpha
}
rejections <- replicate(10000,reject(5))
mean(rejections)
```

The power is very low. Try the above code with higher N and after that, try it with alpha=0.01. The power for alpha=0.05 and N = 30, 60, 90, 120 is 0.4783, 0.7878, 0.9338 and 0.9852, respectively. With alpha=0.01 it is  0.2512, 0.56, 0.7969 and 0.9233, respectively.


### What is the standard error (SE)?
If we take many sample out of a population and take the means of this samples, the standard error is the standard deviation of this distribution of means. As we know from the CLT: If the sample size is large enough (>30), then this distributions is a normal distribution and the SE can be estimated $SE = \frac{s}{\sqrt{N}}$
If the SE is large compared to the sample mean, the mean might not be representative for the population mean.

### What are confidence intervals?
Given a sample (n>30) and the mean of that sample we can calculate the upper and lower boundary of the (in this case 95%) confidence intervals with this formula:
$\overline{x}\pm(1.96*SE)$
We can calculate any other confidence interval by exchanging 1.96 with another z value such as e.g. 2.58 for 99% CI. If we have a smaller sample size we should use t-values instead of z-values.

In 95% of the time, the 95% CI contains the true mean. That means that if we take 10000 random samples of the population and calculate the mean and CI, in 9500 cases the confidence interval contains the true mean.If two confidence intervals do not overlap this indicates that they are from different populations or (in intervention studies) that an intervention induced a difference.

### What is the effect size?
The correlation coefficient r and cohen's d are two popular measures of effect size. R is a good choice generally but Cohen's may be favored in certained situation (for example when group sizes differ a lot). Such standardized effect size measures have the advantage that it does not matter what you are looking at (size in cm or pain scale measure), you can alway interpret the effect size. They also make it easy to combine results of experiments as it is done in a meta-analysis.


```{r}
setw
```

